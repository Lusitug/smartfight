# print("\nTeste1\n")
# print("shape: ", video_keypoints.shape) 
# # 칈ndice	Valor	O que representa
# # 0	        28	      N칰mero de frames no v칤deo
# # 1	         1	      N칰mero de pessoas detectadas por frame (s칩 1 pessoa)
# # 2	        17	      N칰mero de keypoints por pessoa (pontos do corpo)
# # 3	         2	      As coordenadas de cada keypoint: (x, y)

# print("Formato: ", video_keypoints) # Formato 
# # [
# #   [ # Frame 1
# #     [  # Pessoa 1
# #       [x1, y1],  # Keypoint 1
# #       [x2, y2],  # Keypoint 2
# #       ...
# #       [x17, y17]  # Keypoint 17
# #     ]
# #   ],
# #   [ # Frame 2
# #     [  # Pessoa 1
# #       [x1, y1],  # Keypoint 1
# #       [x2, y2],  # Keypoint 2
# #       ...
# #       [x17, y17]  # Keypoint 17
# #     ]
# #   ],
# #   ...
# # ]
# # # video_keypoints[frame][person][keypoint][coord]

# x = video_keypoints[4][0][9][0]  # x do keypoint 10 no frame 5
# y = video_keypoints[4][0][9][1]  # x do keypoint 10 no frame 5
# print("ex: ",x, y)

# ######################

print("\nTeste2\n")

video_keypoints = np.squeeze(video_keypoints, axis=1)
print("shape: ", video_keypoints.shape)  # agora ser치 (28, 17, 2)

print("Formato: ", video_keypoints) # Formato
# # [
# #   [ # Frame 1
# #     [x1, y1],  # Keypoint 1
# #     [x2, y2],  # Keypoint 2
# #     ...
# #     [x17, y17]  # Keypoint 17
# #   ],
# #   [ # Frame 2
# #     [x1, y1],  # Keypoint 1
# #     ...
# #   ],
# #   ...
# # ]
# # # video_keypoints[frame][keypoint][coord]

# x = video_keypoints[4][9][0]  # x do keypoint 10 no frame 5
# y = video_keypoints[4][9][1]  # x do keypoint 10 no frame 5
# print("ex2: ",x, y)



    dataset = DatasetPersonalizado(dataset_csv_path=path_keypoints2csv)
    print(f"TOTAL AMOSTRAS {len(dataset)}")
    x, y = dataset[5]  
    print(f"\n shape do input (x): {x.shape}")  # Ex: torch.Size([28, 34])
    print(f"\n rotulo (y): {y}") 
    loader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, collate_fn=dataset.collate_pad_batch) 
    
    # for i, (x_batch, y_batch) in enumerate(loader):
    #     print(f"\n游대 Lote {i+1}")
    #     print("Shape do x_batch:", x_batch.shape)
    #     print("R칩tulos:", y_batch)

    #     for j in range(len(y_batch)):
    #         rotulo = y_batch[j].item()
    #         nome_classe = dataset.indice_nome(rotulo)
    #         print(f"Amostra {j+1}: r칩tulo={rotulo} -> Classe: {nome_classe}")
    #         break 
   
   
   
    # for i, frame in enumerate(x):  
    #     pares_xy = frame.view(-1, 2)  #[num_keypoints, 2]
    #     print(f"\nFrame {i+1}:")
    #     for j, (x_coord, y_coord) in enumerate(pares_xy):
    #         print(f"Ponto {j}: x={x_coord:.4f}, y={y_coord:.4f}")

    ab = x[34]
    for i in enumerate(ab):
        print(i)

    par = ab.view(-1, 2)
    print(par)

        loader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, collate_fn=dataset.collate_pad_batch) 
    xb, yb = next(iter(loader))
    print ("x batch",xb)
    print ("y batch",yb)

    print(xb[0])
    p = xb[0].view(-1,2)
    print(p)

        def avancando(self ,x, lens):
        print(lens)
        lstm_saida, _ = self.lstm(x)
        lstm_saida = lstm_saida[:, -1, :]
        return self.fully_connected(lstm_saida)

    # for i, (x_batch, y_batch, lens_batch) in enumerate(loader):
    #     print(f"batch {i+1}")
    #     print(f"entradas: {x_batch.shape}")
    #     print(f"rotulos: {y_batch}")
    #     print(f"tamanhos dos frames: {lens_batch}")
